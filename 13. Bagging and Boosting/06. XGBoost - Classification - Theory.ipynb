{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecd2aea",
   "metadata": {},
   "source": [
    "# XGBoost Classification\n",
    "\n",
    "We will consider same data we used for XGBoost Regression with a little bit of modification. Here for classification we will consider 0 when the drug is not effective and 1 when the drug is effective. \n",
    "\n",
    "![](./fig/xgbc.png)\n",
    "\n",
    "As we are using XG boost for classification we have a new formula for calculating similarity scores.\n",
    "\n",
    "$$ Similarity = \\frac{(\\sum Residual_i)^2}{\\sum[previous probability_i * (1 - previous probability_i)] + \\lambda}$$ \n",
    "\n",
    "And we calcualte $$Gain = Left\\ Similarity\\ +\\ Right\\ Similarity\\ - Root\\ Similarity\\$$\n",
    "\n",
    "![](./fig/gain11.png)\n",
    "\n",
    "In a similar manner we calculate gain varying our threshold like we did in regression and we find that **dosage < 15** has the highest gain and we fix it as the first branch in our tree\n",
    "\n",
    "![](./fig/gain22.png)\n",
    "\n",
    "Since like before this threshold of **dosage < 5** gives the highest gain we will choose this as second branch in the tree. Sincewe restrict ourselves to a depth level of 2 we will not split the tree further.\n",
    "\n",
    "The minimum number of residuals in each leaf is calculated by something called **Cover**\n",
    "\n",
    "$$Cover = \\sum[previous\\ probability_i * (1 - previous\\ probability_i)]$$\n",
    "\n",
    "For XGBoost Regression tree cover is $$ Cover\\ =\\  Number\\ of\\ Residuals$$ By default it is 1. Cover has no effect on how we grow tree. But in XGBoost classification things are more complicated as cover depend on previously predicted probability of each residual in leaf. If we set minimum cover to be of value 1, anything less than that is not allowed. And in our current example we for a cover of 1 we wont be having any tree since cover for all the leaves are less than 1. So lets set the cover to zero by **min_child_weight** parameter to 0 \n",
    "\n",
    "**Pruning**\n",
    "\n",
    "Pruning the tree is sumilar to regression if Gain - $\\gamma$ is negative we prune else if its positive we do not prune.\n",
    "\n",
    "**Output values**\n",
    "\n",
    "$$ Output = \\frac{(\\sum Residual_i)}{\\sum[previous probability_i * (1 - previous probability_i)] + \\lambda}$$ \n",
    "\n",
    "After calculating output values we are ready for prediction.\n",
    "\n",
    "![](./fig/final.png)\n",
    "\n",
    "We see the probabily has changed from 0.5 to 0.35. That means our new residual has decreased from 0.5 to 0.35. SImilarly we can calculate new predicted probabilities and residuals to other data points and then repeat the process of fitting another tree to the new residuals. We keep repeating till we have reached maximum number of trees specified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a5d372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
